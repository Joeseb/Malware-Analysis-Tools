from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
import time
import json
import requests
# Path to your ChromeDriver
CHROMEDRIVER_PATH = "C:\Dev\chromedriver-win32\chromedriver.exe"

# Function to scrape data from VirusTotal for a given URL
def scrape_url_report(ip):
    url = f"https://www.virustotal.com/api/v3/ip_addresses/{ip}"

    headers = {"accept": "application/json","x-apikey":"<insert virus total api-key>"}

    response = requests.get(url, headers=headers)
    data=response.json()
    last_analysis_stats = data['data']['attributes']['last_analysis_stats']["malicious"]
    temp={}
    if last_analysis_stats!=0:
        temp['last_analysis_stats']=data['data']['attributes']['last_analysis_stats']
        last_analysis_results = data['data']['attributes']['last_analysis_results']
        for category, result_info in last_analysis_results.items():
            if result_info.get('category') == 'malicious':
                print(f"{category}: {json.dumps(result_info, indent=4)}")
                temp[category]=result_info
        return temp
    return

# Read URLs from a file
def read_urls(file_path):
    with open(file_path, 'r') as file:
        return [line.strip() for line in file]

# Save all reports to a single JSON file
def save_all_reports(reports, file_path):
    with open(file_path, 'w') as file:
        json.dump(reports, file, indent=4)

# Main function
def main():
    url_file_path = 'allIP.txt'  # Path to your file with URLs
    output_file_path = 'all_reports.json'  # Path to save the combined report file
    
    urls = read_urls(url_file_path)
    all_reports = {}
    
    d={}
    for url in urls:
        
        
        report = scrape_url_report(url.strip())
        all_reports[url] = report
        print(f'Report for URL {url} saved.')

        if report:
            print(report)
            d[url]=report
        time.sleep(20)
        print("\n\nd:",d)
    save_all_reports(d, output_file_path)
    print(f'All reports saved to {output_file_path}.')

if __name__ == '__main__':
    main()
