import requests
from bs4 import BeautifulSoup
import json

# Function to scrape WHOIS data
def scrape_whois_data(ip_address):
    url = f"https://www.whois.com/whois/{ip_address}"
    response = requests.get(url)
    
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, 'html.parser')
        pre_tag = soup.find('pre', {'class': 'df-raw', 'id': 'registryData'})
        if pre_tag:
            return pre_tag.text
        else:
            return f"WHOIS data for {ip_address} not found."
    else:
        return f"Failed to retrieve data for {ip_address}. HTTP Status code: {response.status_code}"

ip_addresses = []
# Read IP addresses from the file
with open("allIP.txt", "r") as fp:
    for line in fp:
        ip = line.strip()
        if ip:  # Ensure that empty lines are ignored
            ip_addresses.append(ip)

# Store the results
results = {}

# Scrape WHOIS data for each IP address
for ip in ip_addresses:
    whois_data = scrape_whois_data(ip)
    print(f'Scraping {ip} ...')
    results[ip] = whois_data
    print(f'finished with {ip} moving on to next')

# Print the results
for ip, data in results.items():
    print(f"WHOIS data for {ip}:\n{data}\n")

# Save the results to a JSON file
with open("WHOIS_Data.json", "w") as json_file:
    json.dump(results, json_file, indent=4)

print("WHOIS data saved to WHOIS_Data.json")
